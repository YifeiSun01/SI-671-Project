{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.read_csv(\"filtered_data_197971.csv\", index_col=0)\n",
    "features = [\"SALE TIMES\", \"GROSS LAND RATIO\", 'DAY','MONTH','YEAR',\n",
    "            'BUILDING CLASS CATEGORY', 'ZIP CODE', 'RESIDENTIAL UNITS',\n",
    "            'COMMERCIAL UNITS', 'LAND SQUARE FEET', 'GROSS SQUARE FEET',\n",
    "            \"UPPER BUILDING CLASS AT TIME OF SALE\",\n",
    "            'AGE', 'TAX CLASS AT TIME OF SALE', 'BUILDING CLASS AT TIME OF SALE',\n",
    "            'Latitude', 'Longitude',\"SALE PRICE\"]\n",
    "df_1['SALE DATE'] = pd.to_datetime(df_1['SALE DATE'])\n",
    "df_1['DAY'] = df_1['SALE DATE'].dt.day\n",
    "df_1['MONTH'] = df_1['SALE DATE'].dt.month\n",
    "df_1['YEAR'] = df_1['SALE DATE'].dt.year\n",
    "df_1[\"SALE TIMES\"] = df_1[\"ADDRESS\"].map(df_1[\"ADDRESS\"].value_counts().to_dict())\n",
    "df_1[\"GROSS LAND RATIO\"] = df_1[\"GROSS SQUARE FEET\"]/df_1[\"LAND SQUARE FEET\"]\n",
    "df_1[\"UPPER BUILDING CLASS AT TIME OF SALE\"] = df_1[f\"BUILDING CLASS AT TIME OF SALE\"].str[0]\n",
    "df_1 = df_1[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "from h2o.estimators import H2ORandomForestEstimator\n",
    "from h2o.frame import H2OFrame\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "def get_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred) / np.abs(y_true) * 100)\n",
    "\n",
    "def get_df_dict(df_1,by,category):\n",
    "    category_dict = {\"residential\": [\"A\",\"B\",\"C\",\"D\",'L','R',\"S\"],\n",
    "                    \"house\": [\"A\",\"B\"],\n",
    "                    \"apartment\":[\"C\",\"D\",'L','R',\"S\"],\n",
    "                    \"commercial\":['I','H','J','K','O'],\n",
    "                    \"all\":[chr(ord('a') + i) for i in range(26)]}\n",
    "    month_mapping = {1: 'Jan', 2: 'Feb', 3: 'Mar', 4: 'Apr',\n",
    "                     5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Aug',\n",
    "                     9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dec'}\n",
    "    df_dict = {}\n",
    "    df_1 = df_1[df_1[\"BUILDING CLASS AT TIME OF SALE\"].apply(lambda x: x[0] in category_dict[category])]\n",
    "    if by == \"month\":\n",
    "        for year in sorted(list(set(df_1[\"YEAR\"]))):\n",
    "            for month in sorted(list(set(df_1[\"MONTH\"]))):\n",
    "                df = df_1[(df_1[\"YEAR\"]==year)&(df_1[\"MONTH\"]==month)]\n",
    "                df_dict[\" \".join([str(year),month_mapping[month]])] = df\n",
    "    if by == \"year\":\n",
    "        for year in sorted(list(set(df_1[\"YEAR\"]))):\n",
    "                df = df_1[df_1[\"YEAR\"]==year]\n",
    "                df_dict[str(year)] = df\n",
    "    return df_dict\n",
    "\n",
    "def rf_get_result_cv(df, target):\n",
    "    print(df.shape)\n",
    "    h2o_df = H2OFrame(df)\n",
    "    response_col = target\n",
    "    predictors = [col for col in h2o_df.columns if col != response_col]\n",
    "    train, test = h2o_df.split_frame(ratios=[0.9], seed=42)\n",
    "    rf_model = H2ORandomForestEstimator(\n",
    "        seed=42,\n",
    "        nfolds=5,\n",
    "        keep_cross_validation_predictions=True\n",
    "    )\n",
    "    hyperparameters = {\n",
    "        'ntrees': [10, 20, 30, 50, 100, 150],\n",
    "        'max_depth': [1, 2, 3, 5, 10, 20, 30, 50]\n",
    "    }\n",
    "    grid = H2OGridSearch(rf_model, hyperparameters)\n",
    "    grid.train(x=predictors, y=response_col, training_frame=train)\n",
    "    rf_model = grid.get_grid()[0]\n",
    "    feature_importance = rf_model.varimp()\n",
    "    predictions = rf_model.predict(test).as_data_frame().values\n",
    "    test_response = test.as_data_frame()[response_col].values\n",
    "    mse = rf_model.mse()\n",
    "    mae = rf_model.mae()\n",
    "    percentage_error = get_percentage_error(test_response,predictions)\n",
    "    print(\"mse: \",mse,\"\\n\",\"mae: \",mae,\"\\n\",\"percentage_error: \",percentage_error)\n",
    "    return (mse,mae,percentage_error,feature_importance)\n",
    "\n",
    "def expermient(df_1,by,category,target):\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    percentage_error_list = []\n",
    "    feature_importance_list = []\n",
    "    df_dict = get_df_dict(df_1,by,category)\n",
    "    h2o.init()\n",
    "    for key,val in list(df_dict.items())[:]:\n",
    "        print(key,\"  start\")\n",
    "        start_time = time.time()\n",
    "        mse,mae,percentage_error,feature_importance = rf_get_result_cv(val, target)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "        percentage_error_list.append(percentage_error)\n",
    "        feature_importance_list.append(feature_importance)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "        print(key,\"  end\",\"\\n\\n\")\n",
    "        print(f\"Time: {elapsed_time} seconds\")\n",
    "    return df_dict, mse_list, mae_list, percentage_error_list, feature_importance_list\n",
    "\n",
    "def draw_feature_importance_map(df_dict,feature_importance_list,category,target,by):\n",
    "    flat_feature_importance = [item for sublist in feature_importance_list for item in sublist]\n",
    "    df = pd.DataFrame(flat_feature_importance, columns=['Feature', 'Importance', 'Relative Importance', 'Cumulative Importance'])\n",
    "    feature_num = df_dict[list(df_dict.keys())[0]]-1\n",
    "    df['Year'] = list(chain(*[[key]*feature_num for key in df_dict.keys()]))\n",
    "    df_pivot = df.pivot_table(index='Feature', columns='Year', values='Cumulative Importance', aggfunc='first')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(df_pivot, annot=True, cmap='Blues', fmt=\".2%\", cbar_kws={'label': 'Relative Importance'})\n",
    "    plt.title(title:=f'Feature Importance Heatmap of {target.title()} of {category.title()} Buildings by {by}')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.savefig(\"../plots_2/\"+title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>2 mins 00 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.2</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_DELL_971br6</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.933 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.10.4 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         2 mins 00 secs\n",
       "H2O_cluster_timezone:       America/New_York\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.2\n",
       "H2O_cluster_version_age:    1 month\n",
       "H2O_cluster_name:           H2O_from_python_DELL_971br6\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.933 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.10.4 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016   start\n",
      "(21537, 18)\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m df_1 \u001b[38;5;241m=\u001b[39m df_1[features]\n\u001b[0;32m     19\u001b[0m category,target,by \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhouse\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPRICE PER GROSS AREA\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 20\u001b[0m df_dict, mse_list, mae_list, percentage_error_list, feature_importance_list \u001b[38;5;241m=\u001b[39m \u001b[43mexpermient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m draw_feature_importance_map(df_dict,feature_importance_list,category,target,by)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mexpermient\u001b[1;34m(df_1, by, category, target)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(key,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     71\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 72\u001b[0m mse,mae,percentage_error,feature_importance \u001b[38;5;241m=\u001b[39m \u001b[43mrf_get_result_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m mse_list\u001b[38;5;241m.\u001b[39mappend(mse)\n\u001b[0;32m     74\u001b[0m mae_list\u001b[38;5;241m.\u001b[39mappend(mae)\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mrf_get_result_cv\u001b[1;34m(df, target)\u001b[0m\n\u001b[0;32m     46\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mntrees\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m150\u001b[39m],\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m]\n\u001b[0;32m     49\u001b[0m }\n\u001b[0;32m     50\u001b[0m grid \u001b[38;5;241m=\u001b[39m H2OGridSearch(rf_model, hyperparameters)\n\u001b[1;32m---> 51\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mget_grid()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     53\u001b[0m feature_importance \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mvarimp()\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h2o\\grid\\grid_search.py:353\u001b[0m, in \u001b[0;36mH2OGridSearch.train\u001b[1;34m(self, x, y, training_frame, offset_column, fold_column, weights_column, validation_frame, **params)\u001b[0m\n\u001b[0;32m    351\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(xset)\n\u001b[0;32m    352\u001b[0m parms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 353\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h2o\\grid\\grid_search.py:386\u001b[0m, in \u001b[0;36mH2OGridSearch.build_model\u001b[1;34m(self, algo_params)\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing response\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 386\u001b[0m         y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m training_frame\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mtraining_frame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_estimator_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_frame\u001b[38;5;241m.\u001b[39mtypes[y] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_1 = pd.read_csv(\"filtered_data_197971.csv\", index_col=0)\n",
    "features = [\"SALE TIMES\", \"GROSS LAND RATIO\", 'DAY','MONTH','YEAR',\n",
    "            'BUILDING CLASS CATEGORY', 'ZIP CODE', 'RESIDENTIAL UNITS',\n",
    "            'COMMERCIAL UNITS', 'LAND SQUARE FEET', 'GROSS SQUARE FEET',\n",
    "            \"UPPER BUILDING CLASS AT TIME OF SALE\",\n",
    "            'AGE', 'TAX CLASS AT TIME OF SALE', 'BUILDING CLASS AT TIME OF SALE',\n",
    "            'Latitude', 'Longitude',\"SALE PRICE\"]\n",
    "df_1['SALE DATE'] = pd.to_datetime(df_1['SALE DATE'])\n",
    "df_1['DAY'] = df_1['SALE DATE'].dt.day\n",
    "df_1['MONTH'] = df_1['SALE DATE'].dt.month\n",
    "df_1['YEAR'] = df_1['SALE DATE'].dt.year\n",
    "df_1[\"SALE TIMES\"] = df_1[\"ADDRESS\"].map(df_1[\"ADDRESS\"].value_counts().to_dict())\n",
    "df_1[\"GROSS LAND RATIO\"] = df_1[\"GROSS SQUARE FEET\"]/df_1[\"LAND SQUARE FEET\"]\n",
    "df_1[\"UPPER BUILDING CLASS AT TIME OF SALE\"] = df_1[f\"BUILDING CLASS AT TIME OF SALE\"].str[0]\n",
    "df_1 = df_1[features]\n",
    "\n",
    "category,target,by = \"house\",\"PRICE PER GROSS AREA\",\"year\"\n",
    "df_dict, mse_list, mae_list, percentage_error_list, feature_importance_list = expermient(df_1,by,category,target)\n",
    "draw_feature_importance_map(df_dict,feature_importance_list,category,target,by)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
